{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T14:33:24.568645Z",
     "start_time": "2024-12-22T14:33:23.329952Z"
    }
   },
   "source": [
    "import gymnasium as gym\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:34:03.991518Z",
     "start_time": "2024-12-22T14:34:03.988706Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_episode(env: gym.Env, policy):\n",
    "    state, _ = env.reset()\n",
    "    rewards = []\n",
    "    states = [state]\n",
    "    is_done = False\n",
    "    is_truncated = False\n",
    "    while not is_done and not is_truncated:\n",
    "        action = policy[state].item()\n",
    "        state, reward, is_truncated, is_done, info = env.step(action)\n",
    "        states.append(state)\n",
    "        rewards.append(reward)\n",
    "        if is_done or is_truncated:\n",
    "            break\n",
    "    states = torch.tensor(states)\n",
    "    rewards = torch.tensor(rewards)\n",
    "    return states, rewards\n"
   ],
   "id": "8973766fb1f8c929",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:34:04.742145Z",
     "start_time": "2024-12-22T14:34:04.738197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mc_prediction_first_visit(env, policy, gamma, n_episode):\n",
    "    n_state = policy.shape[0]\n",
    "    V = torch.zeros(n_state)\n",
    "    N = torch.zeros(n_state)\n",
    "    for episode in range(n_episode):\n",
    "        states_t, rewards_t = run_episode(env, policy)\n",
    "        return_t = 0\n",
    "        first_visit = torch.zeros(n_state)\n",
    "        G = torch.zeros(n_state)\n",
    "        for state_t, reward_t in zip(reversed(states_t)[1:], reversed(rewards_t)):\n",
    "            return_t = gamma * return_t + reward_t\n",
    "            G[state_t] = return_t\n",
    "            first_visit[state_t] = 1\n",
    "        for state in range(n_state):\n",
    "            if first_visit[state] > 0:\n",
    "                V[state] += G[state]\n",
    "                N[state] += 1\n",
    "    for state in range(n_state):\n",
    "        if N[state] > 0:\n",
    "            V[state] = V[state] / N[state]\n",
    "    return V\n",
    "\n"
   ],
   "id": "e0a94b1b665c466b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:34:05.463774Z",
     "start_time": "2024-12-22T14:34:05.456654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def mc_prediction_every_visit(env, policy, gamma, n_episode):\n",
    "    n_state = policy.shape[0]\n",
    "    V = torch.zeros(n_state)\n",
    "    N = torch.zeros(n_state)\n",
    "    G = torch.zeros(n_state)\n",
    "    for episode in range(n_episode):\n",
    "        states_t, rewards_t = run_episode(env, policy)\n",
    "        return_t = 0\n",
    "        for state_t, reward_t in zip(reversed(states_t)[1:], reversed(rewards_t)):\n",
    "            return_t = gamma * return_t + reward_t\n",
    "            G[state_t] += return_t\n",
    "            N[state_t] += 1\n",
    "    for state in range(n_state):\n",
    "        if N[state] > 0:\n",
    "            V[state] = G[state] / N[state]\n",
    "    return V"
   ],
   "id": "8ba91f00b144fed2",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:34:15.862454Z",
     "start_time": "2024-12-22T14:34:06.509327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env = gym.make('FrozenLake-v1')\n",
    "gamma = 1\n",
    "n_episode = 10000\n",
    "optimal_policy = torch.tensor([0., 3., 3., 3., 0., 3., 2., 3., 3., 1., 0., 3., 3., 2., 1., 3.])\n",
    "\n",
    "value = mc_prediction_first_visit(env, optimal_policy, gamma, n_episode)\n",
    "print('The value function calculated by first-visit MC prediction:\\n', value)\n"
   ],
   "id": "5324c1a948822b37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value function calculated by first-visit MC prediction:\n",
      " tensor([0.7384, 0.5007, 0.4965, 0.4389, 0.7384, 0.0000, 0.3893, 0.0000, 0.7384,\n",
      "        0.7398, 0.6662, 0.0000, 0.0000, 0.8000, 0.8934, 0.0000])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T14:34:29.028474Z",
     "start_time": "2024-12-22T14:34:18.651980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "value = mc_prediction_every_visit(env, optimal_policy, gamma, n_episode)\n",
    "print('The value function calculated by every-visit MC prediction:\\n', value)\n"
   ],
   "id": "28e0f6ca739dd3df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value function calculated by every-visit MC prediction:\n",
      " tensor([0.6133, 0.4255, 0.3892, 0.3550, 0.6151, 0.0000, 0.3673, 0.0000, 0.6357,\n",
      "        0.6737, 0.6367, 0.0000, 0.0000, 0.7640, 0.8759, 0.0000])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8abb5391aec8cbfd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
